{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "\n",
    "conf = SparkConf().setAppName(\"wordCount_demo\").setMaster(\"local[*]\")\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Download Apache Sparkâ„¢',\n",
       " 'Choose a Spark release: ',\n",
       " '2.4.6 (Jun 05 2020)',\n",
       " '',\n",
       " '',\n",
       " 'Choose a package type: ',\n",
       " 'Pre-built for Apache Hadoop 2.7',\n",
       " '',\n",
       " '',\n",
       " 'Download Spark: spark-3.0.0-preview2-bin-hadoop2.7.tgz',\n",
       " '',\n",
       " 'Verify this release using the 3.0.0-preview2 signatures, checksums and project release KEYS.',\n",
       " '',\n",
       " 'Note that, Spark is pre-built with Scala 2.11 except version 2.4.2, which is pre-built with Scala 2.12.',\n",
       " '',\n",
       " 'Latest Preview Release',\n",
       " 'Preview releases, as the name suggests, are releases for previewing upcoming features. Unlike nightly packages, preview releases have been audited by the projectâ€™s management committee to satisfy the legal requirements of Apache Software Foundationâ€™s release policy. Preview releases are not meant to be functional, i.e. they can and highly likely will contain critical bugs or documentation errors. The latest preview release is Spark 3.0.0-preview2, published on Dec 23, 2019. You can select and download it above.',\n",
       " '',\n",
       " 'Link with Spark',\n",
       " 'Spark artifacts are hosted in Maven Central. You can add a Maven dependency with the following coordinates:',\n",
       " '',\n",
       " 'groupId: org.apache.spark',\n",
       " 'artifactId: spark-core_2.11',\n",
       " 'version: 2.4.6',\n",
       " 'Installing with PyPi',\n",
       " 'PySpark is now available in pypi. To install just run pip install pyspark.',\n",
       " '',\n",
       " 'Release Notes for Stable Releases',\n",
       " 'Spark 3.0.0-preview2 (Dec 23 2019)',\n",
       " 'Spark 2.4.6 (Jun 05 2020)',\n",
       " 'Archived Releases',\n",
       " 'As new Spark releases come out for each development stream, previous ones will be archived, but they are still available at Spark release archives.',\n",
       " '',\n",
       " 'Apache Spark, Spark, Apache, the Apache feather logo, and the Apache Spark project logo are either registered trademarks or trademarks of The Apache Software Foundation in the United States and other countries. See guidance on use of Apache Spark trademarks. All other marks mentioned may be trademarks or registered trademarks of their respective owners. Copyright Â© 2018 The Apache Software Foundation, Licensed under the Apache License, Version 2.0.This is a text File.',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'This is a text file.']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = sc.textFile(\"wordLines.txt\")\n",
    "lines.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Download Apache Sparkâ„¢',\n",
       " 'Choose a Spark release: ',\n",
       " '2.4.6 (Jun 05 2020)',\n",
       " 'Choose a package type: ',\n",
       " 'Pre-built for Apache Hadoop 2.7',\n",
       " 'Download Spark: spark-3.0.0-preview2-bin-hadoop2.7.tgz',\n",
       " 'Verify this release using the 3.0.0-preview2 signatures, checksums and project release KEYS.',\n",
       " 'Note that, Spark is pre-built with Scala 2.11 except version 2.4.2, which is pre-built with Scala 2.12.',\n",
       " 'Latest Preview Release',\n",
       " 'Preview releases, as the name suggests, are releases for previewing upcoming features. Unlike nightly packages, preview releases have been audited by the projectâ€™s management committee to satisfy the legal requirements of Apache Software Foundationâ€™s release policy. Preview releases are not meant to be functional, i.e. they can and highly likely will contain critical bugs or documentation errors. The latest preview release is Spark 3.0.0-preview2, published on Dec 23, 2019. You can select and download it above.',\n",
       " 'Link with Spark',\n",
       " 'Spark artifacts are hosted in Maven Central. You can add a Maven dependency with the following coordinates:',\n",
       " 'groupId: org.apache.spark',\n",
       " 'artifactId: spark-core_2.11',\n",
       " 'version: 2.4.6',\n",
       " 'Installing with PyPi',\n",
       " 'PySpark is now available in pypi. To install just run pip install pyspark.',\n",
       " 'Release Notes for Stable Releases',\n",
       " 'Spark 3.0.0-preview2 (Dec 23 2019)',\n",
       " 'Spark 2.4.6 (Jun 05 2020)',\n",
       " 'Archived Releases',\n",
       " 'As new Spark releases come out for each development stream, previous ones will be archived, but they are still available at Spark release archives.',\n",
       " 'Apache Spark, Spark, Apache, the Apache feather logo, and the Apache Spark project logo are either registered trademarks or trademarks of The Apache Software Foundation in the United States and other countries. See guidance on use of Apache Spark trademarks. All other marks mentioned may be trademarks or registered trademarks of their respective owners. Copyright Â© 2018 The Apache Software Foundation, Licensed under the Apache License, Version 2.0.This is a text File.',\n",
       " 'This is a text file.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_empty_lines = lines.filter(lambda x: x!=\"\")\n",
    "non_empty_lines.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Download',\n",
       " 'Apache',\n",
       " 'Sparkâ„¢',\n",
       " 'Choose',\n",
       " 'a',\n",
       " 'Spark',\n",
       " 'release:',\n",
       " '',\n",
       " '2.4.6',\n",
       " '(Jun',\n",
       " '05',\n",
       " '2020)',\n",
       " 'Choose',\n",
       " 'a',\n",
       " 'package',\n",
       " 'type:',\n",
       " '',\n",
       " 'Pre-built',\n",
       " 'for',\n",
       " 'Apache',\n",
       " 'Hadoop',\n",
       " '2.7',\n",
       " 'Download',\n",
       " 'Spark:',\n",
       " 'spark-3.0.0-preview2-bin-hadoop2.7.tgz',\n",
       " 'Verify',\n",
       " 'this',\n",
       " 'release',\n",
       " 'using',\n",
       " 'the',\n",
       " '3.0.0-preview2',\n",
       " 'signatures,',\n",
       " 'checksums',\n",
       " 'and',\n",
       " 'project',\n",
       " 'release',\n",
       " 'KEYS.',\n",
       " 'Note',\n",
       " 'that,',\n",
       " 'Spark',\n",
       " 'is',\n",
       " 'pre-built',\n",
       " 'with',\n",
       " 'Scala',\n",
       " '2.11',\n",
       " 'except',\n",
       " 'version',\n",
       " '2.4.2,',\n",
       " 'which',\n",
       " 'is',\n",
       " 'pre-built',\n",
       " 'with',\n",
       " 'Scala',\n",
       " '2.12.',\n",
       " 'Latest',\n",
       " 'Preview',\n",
       " 'Release',\n",
       " 'Preview',\n",
       " 'releases,',\n",
       " 'as',\n",
       " 'the',\n",
       " 'name',\n",
       " 'suggests,',\n",
       " 'are',\n",
       " 'releases',\n",
       " 'for',\n",
       " 'previewing',\n",
       " 'upcoming',\n",
       " 'features.',\n",
       " 'Unlike',\n",
       " 'nightly',\n",
       " 'packages,',\n",
       " 'preview',\n",
       " 'releases',\n",
       " 'have',\n",
       " 'been',\n",
       " 'audited',\n",
       " 'by',\n",
       " 'the',\n",
       " 'projectâ€™s',\n",
       " 'management',\n",
       " 'committee',\n",
       " 'to',\n",
       " 'satisfy',\n",
       " 'the',\n",
       " 'legal',\n",
       " 'requirements',\n",
       " 'of',\n",
       " 'Apache',\n",
       " 'Software',\n",
       " 'Foundationâ€™s',\n",
       " 'release',\n",
       " 'policy.',\n",
       " 'Preview',\n",
       " 'releases',\n",
       " 'are',\n",
       " 'not',\n",
       " 'meant',\n",
       " 'to',\n",
       " 'be',\n",
       " 'functional,',\n",
       " 'i.e.',\n",
       " 'they',\n",
       " 'can',\n",
       " 'and',\n",
       " 'highly',\n",
       " 'likely',\n",
       " 'will',\n",
       " 'contain',\n",
       " 'critical',\n",
       " 'bugs',\n",
       " 'or',\n",
       " 'documentation',\n",
       " 'errors.',\n",
       " 'The',\n",
       " 'latest',\n",
       " 'preview',\n",
       " 'release',\n",
       " 'is',\n",
       " 'Spark',\n",
       " '3.0.0-preview2,',\n",
       " 'published',\n",
       " 'on',\n",
       " 'Dec',\n",
       " '23,',\n",
       " '2019.',\n",
       " 'You',\n",
       " 'can',\n",
       " 'select',\n",
       " 'and',\n",
       " 'download',\n",
       " 'it',\n",
       " 'above.',\n",
       " 'Link',\n",
       " 'with',\n",
       " 'Spark',\n",
       " 'Spark',\n",
       " 'artifacts',\n",
       " 'are',\n",
       " 'hosted',\n",
       " 'in',\n",
       " 'Maven',\n",
       " 'Central.',\n",
       " 'You',\n",
       " 'can',\n",
       " 'add',\n",
       " 'a',\n",
       " 'Maven',\n",
       " 'dependency',\n",
       " 'with',\n",
       " 'the',\n",
       " 'following',\n",
       " 'coordinates:',\n",
       " 'groupId:',\n",
       " 'org.apache.spark',\n",
       " 'artifactId:',\n",
       " 'spark-core_2.11',\n",
       " 'version:',\n",
       " '2.4.6',\n",
       " 'Installing',\n",
       " 'with',\n",
       " 'PyPi',\n",
       " 'PySpark',\n",
       " 'is',\n",
       " 'now',\n",
       " 'available',\n",
       " 'in',\n",
       " 'pypi.',\n",
       " 'To',\n",
       " 'install',\n",
       " 'just',\n",
       " 'run',\n",
       " 'pip',\n",
       " 'install',\n",
       " 'pyspark.',\n",
       " 'Release',\n",
       " 'Notes',\n",
       " 'for',\n",
       " 'Stable',\n",
       " 'Releases',\n",
       " 'Spark',\n",
       " '3.0.0-preview2',\n",
       " '(Dec',\n",
       " '23',\n",
       " '2019)',\n",
       " 'Spark',\n",
       " '2.4.6',\n",
       " '(Jun',\n",
       " '05',\n",
       " '2020)',\n",
       " 'Archived',\n",
       " 'Releases',\n",
       " 'As',\n",
       " 'new',\n",
       " 'Spark',\n",
       " 'releases',\n",
       " 'come',\n",
       " 'out',\n",
       " 'for',\n",
       " 'each',\n",
       " 'development',\n",
       " 'stream,',\n",
       " 'previous',\n",
       " 'ones',\n",
       " 'will',\n",
       " 'be',\n",
       " 'archived,',\n",
       " 'but',\n",
       " 'they',\n",
       " 'are',\n",
       " 'still',\n",
       " 'available',\n",
       " 'at',\n",
       " 'Spark',\n",
       " 'release',\n",
       " 'archives.',\n",
       " 'Apache',\n",
       " 'Spark,',\n",
       " 'Spark,',\n",
       " 'Apache,',\n",
       " 'the',\n",
       " 'Apache',\n",
       " 'feather',\n",
       " 'logo,',\n",
       " 'and',\n",
       " 'the',\n",
       " 'Apache',\n",
       " 'Spark',\n",
       " 'project',\n",
       " 'logo',\n",
       " 'are',\n",
       " 'either',\n",
       " 'registered',\n",
       " 'trademarks',\n",
       " 'or',\n",
       " 'trademarks',\n",
       " 'of',\n",
       " 'The',\n",
       " 'Apache',\n",
       " 'Software',\n",
       " 'Foundation',\n",
       " 'in',\n",
       " 'the',\n",
       " 'United',\n",
       " 'States',\n",
       " 'and',\n",
       " 'other',\n",
       " 'countries.',\n",
       " 'See',\n",
       " 'guidance',\n",
       " 'on',\n",
       " 'use',\n",
       " 'of',\n",
       " 'Apache',\n",
       " 'Spark',\n",
       " 'trademarks.',\n",
       " 'All',\n",
       " 'other',\n",
       " 'marks',\n",
       " 'mentioned',\n",
       " 'may',\n",
       " 'be',\n",
       " 'trademarks',\n",
       " 'or',\n",
       " 'registered',\n",
       " 'trademarks',\n",
       " 'of',\n",
       " 'their',\n",
       " 'respective',\n",
       " 'owners.',\n",
       " 'Copyright',\n",
       " 'Â©',\n",
       " '2018',\n",
       " 'The',\n",
       " 'Apache',\n",
       " 'Software',\n",
       " 'Foundation,',\n",
       " 'Licensed',\n",
       " 'under',\n",
       " 'the',\n",
       " 'Apache',\n",
       " 'License,',\n",
       " 'Version',\n",
       " '2.0.This',\n",
       " 'is',\n",
       " 'a',\n",
       " 'text',\n",
       " 'File.',\n",
       " 'This',\n",
       " 'is',\n",
       " 'a',\n",
       " 'text',\n",
       " 'file.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We separate each word as an element of the RDD.\n",
    "\n",
    "words = non_empty_lines.flatMap(lambda x: (x.split(\" \")))\n",
    "\n",
    "words.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Download', 1),\n",
       " ('Apache', 1),\n",
       " ('Sparkâ„¢', 1),\n",
       " ('Choose', 1),\n",
       " ('a', 1),\n",
       " ('Spark', 1),\n",
       " ('release:', 1),\n",
       " ('', 1),\n",
       " ('2.4.6', 1),\n",
       " ('(Jun', 1),\n",
       " ('05', 1),\n",
       " ('2020)', 1),\n",
       " ('Choose', 1),\n",
       " ('a', 1),\n",
       " ('package', 1),\n",
       " ('type:', 1),\n",
       " ('', 1),\n",
       " ('Pre-built', 1),\n",
       " ('for', 1),\n",
       " ('Apache', 1),\n",
       " ('Hadoop', 1),\n",
       " ('2.7', 1),\n",
       " ('Download', 1),\n",
       " ('Spark:', 1),\n",
       " ('spark-3.0.0-preview2-bin-hadoop2.7.tgz', 1),\n",
       " ('Verify', 1),\n",
       " ('this', 1),\n",
       " ('release', 1),\n",
       " ('using', 1),\n",
       " ('the', 1),\n",
       " ('3.0.0-preview2', 1),\n",
       " ('signatures,', 1),\n",
       " ('checksums', 1),\n",
       " ('and', 1),\n",
       " ('project', 1),\n",
       " ('release', 1),\n",
       " ('KEYS.', 1),\n",
       " ('Note', 1),\n",
       " ('that,', 1),\n",
       " ('Spark', 1),\n",
       " ('is', 1),\n",
       " ('pre-built', 1),\n",
       " ('with', 1),\n",
       " ('Scala', 1),\n",
       " ('2.11', 1),\n",
       " ('except', 1),\n",
       " ('version', 1),\n",
       " ('2.4.2,', 1),\n",
       " ('which', 1),\n",
       " ('is', 1),\n",
       " ('pre-built', 1),\n",
       " ('with', 1),\n",
       " ('Scala', 1),\n",
       " ('2.12.', 1),\n",
       " ('Latest', 1),\n",
       " ('Preview', 1),\n",
       " ('Release', 1),\n",
       " ('Preview', 1),\n",
       " ('releases,', 1),\n",
       " ('as', 1),\n",
       " ('the', 1),\n",
       " ('name', 1),\n",
       " ('suggests,', 1),\n",
       " ('are', 1),\n",
       " ('releases', 1),\n",
       " ('for', 1),\n",
       " ('previewing', 1),\n",
       " ('upcoming', 1),\n",
       " ('features.', 1),\n",
       " ('Unlike', 1),\n",
       " ('nightly', 1),\n",
       " ('packages,', 1),\n",
       " ('preview', 1),\n",
       " ('releases', 1),\n",
       " ('have', 1),\n",
       " ('been', 1),\n",
       " ('audited', 1),\n",
       " ('by', 1),\n",
       " ('the', 1),\n",
       " ('projectâ€™s', 1),\n",
       " ('management', 1),\n",
       " ('committee', 1),\n",
       " ('to', 1),\n",
       " ('satisfy', 1),\n",
       " ('the', 1),\n",
       " ('legal', 1),\n",
       " ('requirements', 1),\n",
       " ('of', 1),\n",
       " ('Apache', 1),\n",
       " ('Software', 1),\n",
       " ('Foundationâ€™s', 1),\n",
       " ('release', 1),\n",
       " ('policy.', 1),\n",
       " ('Preview', 1),\n",
       " ('releases', 1),\n",
       " ('are', 1),\n",
       " ('not', 1),\n",
       " ('meant', 1),\n",
       " ('to', 1),\n",
       " ('be', 1),\n",
       " ('functional,', 1),\n",
       " ('i.e.', 1),\n",
       " ('they', 1),\n",
       " ('can', 1),\n",
       " ('and', 1),\n",
       " ('highly', 1),\n",
       " ('likely', 1),\n",
       " ('will', 1),\n",
       " ('contain', 1),\n",
       " ('critical', 1),\n",
       " ('bugs', 1),\n",
       " ('or', 1),\n",
       " ('documentation', 1),\n",
       " ('errors.', 1),\n",
       " ('The', 1),\n",
       " ('latest', 1),\n",
       " ('preview', 1),\n",
       " ('release', 1),\n",
       " ('is', 1),\n",
       " ('Spark', 1),\n",
       " ('3.0.0-preview2,', 1),\n",
       " ('published', 1),\n",
       " ('on', 1),\n",
       " ('Dec', 1),\n",
       " ('23,', 1),\n",
       " ('2019.', 1),\n",
       " ('You', 1),\n",
       " ('can', 1),\n",
       " ('select', 1),\n",
       " ('and', 1),\n",
       " ('download', 1),\n",
       " ('it', 1),\n",
       " ('above.', 1),\n",
       " ('Link', 1),\n",
       " ('with', 1),\n",
       " ('Spark', 1),\n",
       " ('Spark', 1),\n",
       " ('artifacts', 1),\n",
       " ('are', 1),\n",
       " ('hosted', 1),\n",
       " ('in', 1),\n",
       " ('Maven', 1),\n",
       " ('Central.', 1),\n",
       " ('You', 1),\n",
       " ('can', 1),\n",
       " ('add', 1),\n",
       " ('a', 1),\n",
       " ('Maven', 1),\n",
       " ('dependency', 1),\n",
       " ('with', 1),\n",
       " ('the', 1),\n",
       " ('following', 1),\n",
       " ('coordinates:', 1),\n",
       " ('groupId:', 1),\n",
       " ('org.apache.spark', 1),\n",
       " ('artifactId:', 1),\n",
       " ('spark-core_2.11', 1),\n",
       " ('version:', 1),\n",
       " ('2.4.6', 1),\n",
       " ('Installing', 1),\n",
       " ('with', 1),\n",
       " ('PyPi', 1),\n",
       " ('PySpark', 1),\n",
       " ('is', 1),\n",
       " ('now', 1),\n",
       " ('available', 1),\n",
       " ('in', 1),\n",
       " ('pypi.', 1),\n",
       " ('To', 1),\n",
       " ('install', 1),\n",
       " ('just', 1),\n",
       " ('run', 1),\n",
       " ('pip', 1),\n",
       " ('install', 1),\n",
       " ('pyspark.', 1),\n",
       " ('Release', 1),\n",
       " ('Notes', 1),\n",
       " ('for', 1),\n",
       " ('Stable', 1),\n",
       " ('Releases', 1),\n",
       " ('Spark', 1),\n",
       " ('3.0.0-preview2', 1),\n",
       " ('(Dec', 1),\n",
       " ('23', 1),\n",
       " ('2019)', 1),\n",
       " ('Spark', 1),\n",
       " ('2.4.6', 1),\n",
       " ('(Jun', 1),\n",
       " ('05', 1),\n",
       " ('2020)', 1),\n",
       " ('Archived', 1),\n",
       " ('Releases', 1),\n",
       " ('As', 1),\n",
       " ('new', 1),\n",
       " ('Spark', 1),\n",
       " ('releases', 1),\n",
       " ('come', 1),\n",
       " ('out', 1),\n",
       " ('for', 1),\n",
       " ('each', 1),\n",
       " ('development', 1),\n",
       " ('stream,', 1),\n",
       " ('previous', 1),\n",
       " ('ones', 1),\n",
       " ('will', 1),\n",
       " ('be', 1),\n",
       " ('archived,', 1),\n",
       " ('but', 1),\n",
       " ('they', 1),\n",
       " ('are', 1),\n",
       " ('still', 1),\n",
       " ('available', 1),\n",
       " ('at', 1),\n",
       " ('Spark', 1),\n",
       " ('release', 1),\n",
       " ('archives.', 1),\n",
       " ('Apache', 1),\n",
       " ('Spark,', 1),\n",
       " ('Spark,', 1),\n",
       " ('Apache,', 1),\n",
       " ('the', 1),\n",
       " ('Apache', 1),\n",
       " ('feather', 1),\n",
       " ('logo,', 1),\n",
       " ('and', 1),\n",
       " ('the', 1),\n",
       " ('Apache', 1),\n",
       " ('Spark', 1),\n",
       " ('project', 1),\n",
       " ('logo', 1),\n",
       " ('are', 1),\n",
       " ('either', 1),\n",
       " ('registered', 1),\n",
       " ('trademarks', 1),\n",
       " ('or', 1),\n",
       " ('trademarks', 1),\n",
       " ('of', 1),\n",
       " ('The', 1),\n",
       " ('Apache', 1),\n",
       " ('Software', 1),\n",
       " ('Foundation', 1),\n",
       " ('in', 1),\n",
       " ('the', 1),\n",
       " ('United', 1),\n",
       " ('States', 1),\n",
       " ('and', 1),\n",
       " ('other', 1),\n",
       " ('countries.', 1),\n",
       " ('See', 1),\n",
       " ('guidance', 1),\n",
       " ('on', 1),\n",
       " ('use', 1),\n",
       " ('of', 1),\n",
       " ('Apache', 1),\n",
       " ('Spark', 1),\n",
       " ('trademarks.', 1),\n",
       " ('All', 1),\n",
       " ('other', 1),\n",
       " ('marks', 1),\n",
       " ('mentioned', 1),\n",
       " ('may', 1),\n",
       " ('be', 1),\n",
       " ('trademarks', 1),\n",
       " ('or', 1),\n",
       " ('registered', 1),\n",
       " ('trademarks', 1),\n",
       " ('of', 1),\n",
       " ('their', 1),\n",
       " ('respective', 1),\n",
       " ('owners.', 1),\n",
       " ('Copyright', 1),\n",
       " ('Â©', 1),\n",
       " ('2018', 1),\n",
       " ('The', 1),\n",
       " ('Apache', 1),\n",
       " ('Software', 1),\n",
       " ('Foundation,', 1),\n",
       " ('Licensed', 1),\n",
       " ('under', 1),\n",
       " ('the', 1),\n",
       " ('Apache', 1),\n",
       " ('License,', 1),\n",
       " ('Version', 1),\n",
       " ('2.0.This', 1),\n",
       " ('is', 1),\n",
       " ('a', 1),\n",
       " ('text', 1),\n",
       " ('File.', 1),\n",
       " ('This', 1),\n",
       " ('is', 1),\n",
       " ('a', 1),\n",
       " ('text', 1),\n",
       " ('file.', 1)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Each word is an element of the RDD. We make this RDD a paired RDD.\n",
    "\n",
    "paired_rdd = words.map(lambda x:(x,1))\n",
    "\n",
    "paired_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Apache', 10),\n",
       " ('Sparkâ„¢', 1),\n",
       " ('Choose', 2),\n",
       " ('Spark', 11),\n",
       " ('', 2),\n",
       " ('2.4.6', 3),\n",
       " ('05', 2),\n",
       " ('type:', 1),\n",
       " ('2.7', 1),\n",
       " ('spark-3.0.0-preview2-bin-hadoop2.7.tgz', 1),\n",
       " ('Verify', 1),\n",
       " ('this', 1),\n",
       " ('using', 1),\n",
       " ('project', 2),\n",
       " ('KEYS.', 1),\n",
       " ('Note', 1),\n",
       " ('that,', 1),\n",
       " ('is', 6),\n",
       " ('version', 1),\n",
       " ('2.12.', 1),\n",
       " ('Preview', 3),\n",
       " ('releases,', 1),\n",
       " ('as', 1),\n",
       " ('name', 1),\n",
       " ('suggests,', 1),\n",
       " ('are', 5),\n",
       " ('Unlike', 1),\n",
       " ('nightly', 1),\n",
       " ('packages,', 1),\n",
       " ('preview', 2),\n",
       " ('have', 1),\n",
       " ('management', 1),\n",
       " ('legal', 1),\n",
       " ('requirements', 1),\n",
       " ('of', 4),\n",
       " ('Foundationâ€™s', 1),\n",
       " ('functional,', 1),\n",
       " ('i.e.', 1),\n",
       " ('likely', 1),\n",
       " ('documentation', 1),\n",
       " ('errors.', 1),\n",
       " ('The', 3),\n",
       " ('latest', 1),\n",
       " ('published', 1),\n",
       " ('23,', 1),\n",
       " ('2019.', 1),\n",
       " ('select', 1),\n",
       " ('Link', 1),\n",
       " ('artifacts', 1),\n",
       " ('in', 3),\n",
       " ('Maven', 2),\n",
       " ('Central.', 1),\n",
       " ('following', 1),\n",
       " ('coordinates:', 1),\n",
       " ('groupId:', 1),\n",
       " ('org.apache.spark', 1),\n",
       " ('spark-core_2.11', 1),\n",
       " ('version:', 1),\n",
       " ('PyPi', 1),\n",
       " ('PySpark', 1),\n",
       " ('now', 1),\n",
       " ('install', 2),\n",
       " ('just', 1),\n",
       " ('run', 1),\n",
       " ('pip', 1),\n",
       " ('Notes', 1),\n",
       " ('Stable', 1),\n",
       " ('new', 1),\n",
       " ('out', 1),\n",
       " ('development', 1),\n",
       " ('archived,', 1),\n",
       " ('but', 1),\n",
       " ('at', 1),\n",
       " ('Spark,', 2),\n",
       " ('Apache,', 1),\n",
       " ('feather', 1),\n",
       " ('registered', 2),\n",
       " ('trademarks', 4),\n",
       " ('United', 1),\n",
       " ('States', 1),\n",
       " ('other', 2),\n",
       " ('guidance', 1),\n",
       " ('use', 1),\n",
       " ('trademarks.', 1),\n",
       " ('may', 1),\n",
       " ('respective', 1),\n",
       " ('2.0.This', 1),\n",
       " ('File.', 1),\n",
       " ('file.', 1),\n",
       " ('Download', 2),\n",
       " ('a', 5),\n",
       " ('release:', 1),\n",
       " ('(Jun', 2),\n",
       " ('2020)', 2),\n",
       " ('package', 1),\n",
       " ('Pre-built', 1),\n",
       " ('for', 4),\n",
       " ('Hadoop', 1),\n",
       " ('Spark:', 1),\n",
       " ('release', 5),\n",
       " ('the', 9),\n",
       " ('3.0.0-preview2', 2),\n",
       " ('signatures,', 1),\n",
       " ('checksums', 1),\n",
       " ('and', 5),\n",
       " ('pre-built', 2),\n",
       " ('with', 5),\n",
       " ('Scala', 2),\n",
       " ('2.11', 1),\n",
       " ('except', 1),\n",
       " ('2.4.2,', 1),\n",
       " ('which', 1),\n",
       " ('Latest', 1),\n",
       " ('Release', 2),\n",
       " ('releases', 4),\n",
       " ('previewing', 1),\n",
       " ('upcoming', 1),\n",
       " ('features.', 1),\n",
       " ('been', 1),\n",
       " ('audited', 1),\n",
       " ('by', 1),\n",
       " ('projectâ€™s', 1),\n",
       " ('committee', 1),\n",
       " ('to', 2),\n",
       " ('satisfy', 1),\n",
       " ('Software', 3),\n",
       " ('policy.', 1),\n",
       " ('not', 1),\n",
       " ('meant', 1),\n",
       " ('be', 3),\n",
       " ('they', 2),\n",
       " ('can', 3),\n",
       " ('highly', 1),\n",
       " ('will', 2),\n",
       " ('contain', 1),\n",
       " ('critical', 1),\n",
       " ('bugs', 1),\n",
       " ('or', 3),\n",
       " ('3.0.0-preview2,', 1),\n",
       " ('on', 2),\n",
       " ('Dec', 1),\n",
       " ('You', 2),\n",
       " ('download', 1),\n",
       " ('it', 1),\n",
       " ('above.', 1),\n",
       " ('hosted', 1),\n",
       " ('add', 1),\n",
       " ('dependency', 1),\n",
       " ('artifactId:', 1),\n",
       " ('Installing', 1),\n",
       " ('available', 2),\n",
       " ('pypi.', 1),\n",
       " ('To', 1),\n",
       " ('pyspark.', 1),\n",
       " ('Releases', 2),\n",
       " ('(Dec', 1),\n",
       " ('23', 1),\n",
       " ('2019)', 1),\n",
       " ('Archived', 1),\n",
       " ('As', 1),\n",
       " ('come', 1),\n",
       " ('each', 1),\n",
       " ('stream,', 1),\n",
       " ('previous', 1),\n",
       " ('ones', 1),\n",
       " ('still', 1),\n",
       " ('archives.', 1),\n",
       " ('logo,', 1),\n",
       " ('logo', 1),\n",
       " ('either', 1),\n",
       " ('Foundation', 1),\n",
       " ('countries.', 1),\n",
       " ('See', 1),\n",
       " ('All', 1),\n",
       " ('marks', 1),\n",
       " ('mentioned', 1),\n",
       " ('their', 1),\n",
       " ('owners.', 1),\n",
       " ('Copyright', 1),\n",
       " ('Â©', 1),\n",
       " ('2018', 1),\n",
       " ('Foundation,', 1),\n",
       " ('Licensed', 1),\n",
       " ('under', 1),\n",
       " ('License,', 1),\n",
       " ('Version', 1),\n",
       " ('text', 2),\n",
       " ('This', 1)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "words_with_count = paired_rdd.reduceByKey(lambda x,y:x+y)\n",
    "\n",
    "words_with_count.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'Download': 2,\n",
       "             'Apache': 10,\n",
       "             'Sparkâ„¢': 1,\n",
       "             'Choose': 2,\n",
       "             'a': 5,\n",
       "             'Spark': 11,\n",
       "             'release:': 1,\n",
       "             '': 2,\n",
       "             '2.4.6': 3,\n",
       "             '(Jun': 2,\n",
       "             '05': 2,\n",
       "             '2020)': 2,\n",
       "             'package': 1,\n",
       "             'type:': 1,\n",
       "             'Pre-built': 1,\n",
       "             'for': 4,\n",
       "             'Hadoop': 1,\n",
       "             '2.7': 1,\n",
       "             'Spark:': 1,\n",
       "             'spark-3.0.0-preview2-bin-hadoop2.7.tgz': 1,\n",
       "             'Verify': 1,\n",
       "             'this': 1,\n",
       "             'release': 5,\n",
       "             'using': 1,\n",
       "             'the': 9,\n",
       "             '3.0.0-preview2': 2,\n",
       "             'signatures,': 1,\n",
       "             'checksums': 1,\n",
       "             'and': 5,\n",
       "             'project': 2,\n",
       "             'KEYS.': 1,\n",
       "             'Note': 1,\n",
       "             'that,': 1,\n",
       "             'is': 6,\n",
       "             'pre-built': 2,\n",
       "             'with': 5,\n",
       "             'Scala': 2,\n",
       "             '2.11': 1,\n",
       "             'except': 1,\n",
       "             'version': 1,\n",
       "             '2.4.2,': 1,\n",
       "             'which': 1,\n",
       "             '2.12.': 1,\n",
       "             'Latest': 1,\n",
       "             'Preview': 3,\n",
       "             'Release': 2,\n",
       "             'releases,': 1,\n",
       "             'as': 1,\n",
       "             'name': 1,\n",
       "             'suggests,': 1,\n",
       "             'are': 5,\n",
       "             'releases': 4,\n",
       "             'previewing': 1,\n",
       "             'upcoming': 1,\n",
       "             'features.': 1,\n",
       "             'Unlike': 1,\n",
       "             'nightly': 1,\n",
       "             'packages,': 1,\n",
       "             'preview': 2,\n",
       "             'have': 1,\n",
       "             'been': 1,\n",
       "             'audited': 1,\n",
       "             'by': 1,\n",
       "             'projectâ€™s': 1,\n",
       "             'management': 1,\n",
       "             'committee': 1,\n",
       "             'to': 2,\n",
       "             'satisfy': 1,\n",
       "             'legal': 1,\n",
       "             'requirements': 1,\n",
       "             'of': 4,\n",
       "             'Software': 3,\n",
       "             'Foundationâ€™s': 1,\n",
       "             'policy.': 1,\n",
       "             'not': 1,\n",
       "             'meant': 1,\n",
       "             'be': 3,\n",
       "             'functional,': 1,\n",
       "             'i.e.': 1,\n",
       "             'they': 2,\n",
       "             'can': 3,\n",
       "             'highly': 1,\n",
       "             'likely': 1,\n",
       "             'will': 2,\n",
       "             'contain': 1,\n",
       "             'critical': 1,\n",
       "             'bugs': 1,\n",
       "             'or': 3,\n",
       "             'documentation': 1,\n",
       "             'errors.': 1,\n",
       "             'The': 3,\n",
       "             'latest': 1,\n",
       "             '3.0.0-preview2,': 1,\n",
       "             'published': 1,\n",
       "             'on': 2,\n",
       "             'Dec': 1,\n",
       "             '23,': 1,\n",
       "             '2019.': 1,\n",
       "             'You': 2,\n",
       "             'select': 1,\n",
       "             'download': 1,\n",
       "             'it': 1,\n",
       "             'above.': 1,\n",
       "             'Link': 1,\n",
       "             'artifacts': 1,\n",
       "             'hosted': 1,\n",
       "             'in': 3,\n",
       "             'Maven': 2,\n",
       "             'Central.': 1,\n",
       "             'add': 1,\n",
       "             'dependency': 1,\n",
       "             'following': 1,\n",
       "             'coordinates:': 1,\n",
       "             'groupId:': 1,\n",
       "             'org.apache.spark': 1,\n",
       "             'artifactId:': 1,\n",
       "             'spark-core_2.11': 1,\n",
       "             'version:': 1,\n",
       "             'Installing': 1,\n",
       "             'PyPi': 1,\n",
       "             'PySpark': 1,\n",
       "             'now': 1,\n",
       "             'available': 2,\n",
       "             'pypi.': 1,\n",
       "             'To': 1,\n",
       "             'install': 2,\n",
       "             'just': 1,\n",
       "             'run': 1,\n",
       "             'pip': 1,\n",
       "             'pyspark.': 1,\n",
       "             'Notes': 1,\n",
       "             'Stable': 1,\n",
       "             'Releases': 2,\n",
       "             '(Dec': 1,\n",
       "             '23': 1,\n",
       "             '2019)': 1,\n",
       "             'Archived': 1,\n",
       "             'As': 1,\n",
       "             'new': 1,\n",
       "             'come': 1,\n",
       "             'out': 1,\n",
       "             'each': 1,\n",
       "             'development': 1,\n",
       "             'stream,': 1,\n",
       "             'previous': 1,\n",
       "             'ones': 1,\n",
       "             'archived,': 1,\n",
       "             'but': 1,\n",
       "             'still': 1,\n",
       "             'at': 1,\n",
       "             'archives.': 1,\n",
       "             'Spark,': 2,\n",
       "             'Apache,': 1,\n",
       "             'feather': 1,\n",
       "             'logo,': 1,\n",
       "             'logo': 1,\n",
       "             'either': 1,\n",
       "             'registered': 2,\n",
       "             'trademarks': 4,\n",
       "             'Foundation': 1,\n",
       "             'United': 1,\n",
       "             'States': 1,\n",
       "             'other': 2,\n",
       "             'countries.': 1,\n",
       "             'See': 1,\n",
       "             'guidance': 1,\n",
       "             'use': 1,\n",
       "             'trademarks.': 1,\n",
       "             'All': 1,\n",
       "             'marks': 1,\n",
       "             'mentioned': 1,\n",
       "             'may': 1,\n",
       "             'their': 1,\n",
       "             'respective': 1,\n",
       "             'owners.': 1,\n",
       "             'Copyright': 1,\n",
       "             'Â©': 1,\n",
       "             '2018': 1,\n",
       "             'Foundation,': 1,\n",
       "             'Licensed': 1,\n",
       "             'under': 1,\n",
       "             'License,': 1,\n",
       "             'Version': 1,\n",
       "             '2.0.This': 1,\n",
       "             'text': 2,\n",
       "             'File.': 1,\n",
       "             'This': 1,\n",
       "             'file.': 1})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.countByValue()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User Pin Case Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rohit, Photography',\n",
       " 'Rohit, Photo Creation',\n",
       " 'Rohit, Adobe Effects',\n",
       " 'Rohit, Video Editing',\n",
       " 'Rohit, Youtube video making',\n",
       " '',\n",
       " 'Rahul, Photography',\n",
       " 'Rahul, Instagram growth',\n",
       " 'Rahul, Photo Creation',\n",
       " 'Rahul, digital marketing',\n",
       " 'Rahul, Blogging',\n",
       " '',\n",
       " 'Sachin, Photo Creation',\n",
       " 'Sachin, Blogging',\n",
       " 'Sachin, Adobe Effects',\n",
       " 'Sachin, Video Editing',\n",
       " 'Sachin, Youtube video making',\n",
       " '',\n",
       " 'Saurav, Youtube video making',\n",
       " 'Saurav, UI/UX designs',\n",
       " 'Saurav, Instagram growth',\n",
       " 'Saurav, Web development',\n",
       " 'Saurav, Blogging',\n",
       " '',\n",
       " 'Irfan, UI/UX designs',\n",
       " 'Irfan, Web development',\n",
       " 'Irfan, Blogging',\n",
       " 'Irfan, Adobe Effects',\n",
       " 'Irfan, Video Editing']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file1 = sc.textFile(\"UserPins.txt\")\n",
    "file1.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rohit, Photography',\n",
       " 'Rohit, Web development',\n",
       " '',\n",
       " 'Rahul, Photography',\n",
       " 'Rahul, Instagram growth',\n",
       " '',\n",
       " 'Sachin, Photography',\n",
       " 'Sachin, Instagram growth',\n",
       " 'Sachin, Adobe Effects',\n",
       " '',\n",
       " 'Irfan, Photography',\n",
       " 'Irfan, Instagram growth']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file2 = sc.textFile(\"UserSearch.txt\")\n",
    "file2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rohit, Photography',\n",
       " 'Rohit, Photo Creation',\n",
       " 'Rohit, Adobe Effects',\n",
       " 'Rohit, Video Editing',\n",
       " 'Rohit, Youtube video making',\n",
       " 'Rahul, Photography',\n",
       " 'Rahul, Instagram growth',\n",
       " 'Rahul, Photo Creation',\n",
       " 'Rahul, digital marketing',\n",
       " 'Rahul, Blogging',\n",
       " 'Sachin, Photo Creation',\n",
       " 'Sachin, Blogging',\n",
       " 'Sachin, Adobe Effects',\n",
       " 'Sachin, Video Editing',\n",
       " 'Sachin, Youtube video making',\n",
       " 'Saurav, Youtube video making',\n",
       " 'Saurav, UI/UX designs',\n",
       " 'Saurav, Instagram growth',\n",
       " 'Saurav, Web development',\n",
       " 'Saurav, Blogging',\n",
       " 'Irfan, UI/UX designs',\n",
       " 'Irfan, Web development',\n",
       " 'Irfan, Blogging',\n",
       " 'Irfan, Adobe Effects',\n",
       " 'Irfan, Video Editing']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file1_without_empty_line = file1.filter(lambda x:x!=\"\")\n",
    "file1_without_empty_line.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rohit, Photography',\n",
       " 'Rohit, Web development',\n",
       " 'Rahul, Photography',\n",
       " 'Rahul, Instagram growth',\n",
       " 'Sachin, Photography',\n",
       " 'Sachin, Instagram growth',\n",
       " 'Sachin, Adobe Effects',\n",
       " 'Irfan, Photography',\n",
       " 'Irfan, Instagram growth']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file2_without_empty_line = file2.filter(lambda x:x!=\"\")\n",
    "file2_without_empty_line.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Rohit', 'Photography'],\n",
       " ['Rohit', 'Photo Creation'],\n",
       " ['Rohit', 'Adobe Effects'],\n",
       " ['Rohit', 'Video Editing'],\n",
       " ['Rohit', 'Youtube video making'],\n",
       " ['Rahul', 'Photography'],\n",
       " ['Rahul', 'Instagram growth'],\n",
       " ['Rahul', 'Photo Creation'],\n",
       " ['Rahul', 'digital marketing'],\n",
       " ['Rahul', 'Blogging'],\n",
       " ['Sachin', 'Photo Creation'],\n",
       " ['Sachin', 'Blogging'],\n",
       " ['Sachin', 'Adobe Effects'],\n",
       " ['Sachin', 'Video Editing'],\n",
       " ['Sachin', 'Youtube video making'],\n",
       " ['Saurav', 'Youtube video making'],\n",
       " ['Saurav', 'UI/UX designs'],\n",
       " ['Saurav', 'Instagram growth'],\n",
       " ['Saurav', 'Web development'],\n",
       " ['Saurav', 'Blogging'],\n",
       " ['Irfan', 'UI/UX designs'],\n",
       " ['Irfan', 'Web development'],\n",
       " ['Irfan', 'Blogging'],\n",
       " ['Irfan', 'Adobe Effects'],\n",
       " ['Irfan', 'Video Editing']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file1_array = file1_without_empty_line.map(lambda x: x.split(\", \"))\n",
    "file1_array.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Rohit', 'Photography'],\n",
       " ['Rohit', 'Web development'],\n",
       " ['Rahul', 'Photography'],\n",
       " ['Rahul', 'Instagram growth'],\n",
       " ['Sachin', 'Photography'],\n",
       " ['Sachin', 'Instagram growth'],\n",
       " ['Sachin', 'Adobe Effects'],\n",
       " ['Irfan', 'Photography'],\n",
       " ['Irfan', 'Instagram growth']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file2_array = file2_without_empty_line.map(lambda x: x.split(\", \"))\n",
    "file2_array.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Rohit', 'Photography'),\n",
       " ('Rohit', 'Photo Creation'),\n",
       " ('Rohit', 'Adobe Effects'),\n",
       " ('Rohit', 'Video Editing'),\n",
       " ('Rohit', 'Youtube video making'),\n",
       " ('Rahul', 'Photography'),\n",
       " ('Rahul', 'Instagram growth'),\n",
       " ('Rahul', 'Photo Creation'),\n",
       " ('Rahul', 'digital marketing'),\n",
       " ('Rahul', 'Blogging'),\n",
       " ('Sachin', 'Photo Creation'),\n",
       " ('Sachin', 'Blogging'),\n",
       " ('Sachin', 'Adobe Effects'),\n",
       " ('Sachin', 'Video Editing'),\n",
       " ('Sachin', 'Youtube video making'),\n",
       " ('Saurav', 'Youtube video making'),\n",
       " ('Saurav', 'UI/UX designs'),\n",
       " ('Saurav', 'Instagram growth'),\n",
       " ('Saurav', 'Web development'),\n",
       " ('Saurav', 'Blogging'),\n",
       " ('Irfan', 'UI/UX designs'),\n",
       " ('Irfan', 'Web development'),\n",
       " ('Irfan', 'Blogging'),\n",
       " ('Irfan', 'Adobe Effects'),\n",
       " ('Irfan', 'Video Editing')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userInfo = file1_array.map(lambda x: (x[0],x[1]))\n",
    "userInfo.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Rohit', 'Photography'),\n",
       " ('Rohit', 'Web development'),\n",
       " ('Rahul', 'Photography'),\n",
       " ('Rahul', 'Instagram growth'),\n",
       " ('Sachin', 'Photography'),\n",
       " ('Sachin', 'Instagram growth'),\n",
       " ('Sachin', 'Adobe Effects'),\n",
       " ('Irfan', 'Photography'),\n",
       " ('Irfan', 'Instagram growth')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "linkInfo = file2_array.map(lambda x: (x[0],x[1]))\n",
    "linkInfo.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Rahul', 'Photography'),\n",
       " ('Rohit', 'Photography'),\n",
       " ('Rahul', 'Instagram growth'),\n",
       " ('Sachin', 'Adobe Effects')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_interest = linkInfo.intersection(userInfo)\n",
    "old_interest.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Sachin', 'Instagram growth'),\n",
       " ('Sachin', 'Photography'),\n",
       " ('Irfan', 'Photography'),\n",
       " ('Rohit', 'Web development'),\n",
       " ('Irfan', 'Instagram growth')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_interest = linkInfo.subtract(userInfo)\n",
    "new_interest.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Irfan', 'Photography'),\n",
       " ('Irfan', 'Instagram growth'),\n",
       " ('Rohit', 'Web development'),\n",
       " ('Sachin', 'Instagram growth'),\n",
       " ('Sachin', 'Photography')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_interest_sorted = new_interest.sortByKey()\n",
    "new_interest_sorted.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "rdd1 = sc.parallelize([('a', 10), ('b', 15),('a',5),('c', 12),('b',6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10.5, 7.5, 12.0]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_by_key=rdd1.mapValues(lambda x: (x, 1)).reduceByKey(lambda a,b: (a[0]+b[0], a[1]+b[1])).map(lambda v: v[1][0]/v[1][1])\n",
    "avg_by_key.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
